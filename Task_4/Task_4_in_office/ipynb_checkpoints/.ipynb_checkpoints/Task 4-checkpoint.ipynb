{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScXd2zhs6fFq"
   },
   "source": [
    "# Week 4 Assignment\n",
    "- **Assignment Description** The overall goal of this assignment is to use LSTM to recognize named entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uCzgqJk7AiN"
   },
   "source": [
    "## Data File Description\n",
    "\n",
    "The dataset is about adverse reactions to pharmaceutical psychiatric treatment. The dataset covers patients' expression of effectiveness and adverse drug events associated with four psychiatric medications.  It uses the same dataset as the Week 3 assignment.\n",
    "\n",
    "For this assignment, you will need files list below.\n",
    "```\n",
    "/review_data\n",
    "    REVIEW_LABELSEQ.txt\n",
    "    REVIEW_TEXT.txt\n",
    "    TEST_REVIEW_TEXT.txt\n",
    "```\n",
    "\n",
    "1. `REVIEW_TEXT.txt`\n",
    "> The training file contains 4,744 sentences coming from 711 reviews. You can find that all patients' reviews are splitted by sentence, and the file haas two columns. One of the columns is the ID for each sentence which is labeled as `<Medication>.<Post_number>.<Sentence_number>`. The other column is the splitted sentence itself. \n",
    "  > Here is an example row of this dataset.\n",
    "\n",
    "  >  `8<tab>Tobacco cravings were rampant .`\n",
    "  \n",
    "\n",
    "\n",
    "2. `REVIEW_LABELSEQ.txt`\n",
    "> You can find there are two columns, ID and TAGSEQ. ID is the same unique string as previous file. TAGSEQ is a sequence of sapce-separated named-entity tages that are either `O` or `B-AE`, `I-AE`, `B-SSI`, `I-SSI`. These tags are explained as below.\n",
    "  - `AE`: adverse events (entity of interest)\n",
    "  - `SSI`: signs, symptoms, and indications (entity of interest)\n",
    "  - `B-`: beginning of a tagged named entity\n",
    "  - `I-`: inside a tagged named entity\n",
    "  - `O` : outside of any tagged named entity\n",
    "\n",
    "  > Here is an example row of this file.\n",
    "\n",
    "  >  `8    B-AE I-AE I-AE I-AE O `\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7iHhnVoaxq7"
   },
   "source": [
    "## Code Template\n",
    "Please modify code templates as much as you want. If you find using a function would be more useful, please use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D7h1n-hWaxq_"
   },
   "outputs": [],
   "source": [
    "def read_file(f):\n",
    "    \"\"\"This function is used to read files that are tab-separated. \n",
    "    The function will split each row into two parts: ID and data.\n",
    "    Data is a list of either sentence or tag sequence that is splitted into a list by space. \n",
    "    \"\"\"\n",
    "    data = open(f,'r').readlines()[1:]\n",
    "    row_id = [i.split('\\t')[0].strip() for i in data]\n",
    "    data = [i.split('\\t')[1].strip().split(' ') for i in data]\n",
    "    return row_id,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dUgJRS_8axrB"
   },
   "outputs": [],
   "source": [
    "row_id_text, texts = read_file('./data/REVIEW_TEXT.txt')\n",
    "row_id_tags, tags = read_file('./data/REVIEW_LABELSEQ.txt')\n",
    "\n",
    "#texts = texts[:5000]  \n",
    "#tags = tags[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get GloVe word embeddings\n",
    "\n",
    "You do not need to have a deep understanding of word embeddings! &nbsp;Roughly speaking, these word embeddings transform each token into a vector of numbers, based on their distribution in a (separate) large dataset.&nbsp; So, these embeddings were trained by someone else already!&nbsp; We can think of the values in the vector as features of a word.&nbsp; The ordered set of word feature vectors make up the input for each sentence.&nbsp; The input to the models we will use is just different kinds of features compared to what we used for the last assignment.&nbsp; We are simply importing these embeddings because the deep learning methods will perform much better using these instead of treating each word as an arbitrary categorical value.&nbsp; Using embeddings like these is is a standard way of doing natural language processing tasks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextVectorization\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_tensor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "import numpy as np\n",
    "from tensorflow import convert_to_tensor\n",
    "from functools import reduce\n",
    "import operator\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "vectorizer = TextVectorization(max_tokens=8000, pad_to_max_tokens=False)\n",
    "vectorizer.adapt(convert_to_tensor(reduce(operator.concat, texts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))\n",
    "print(len(voc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import GloVe Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYm8-X5_axrG",
    "outputId": "6044e266-1a32-4d8a-9e80-a1d2f76e7cc6"
   },
   "outputs": [],
   "source": [
    "path_to_glove_file = \"./data/glove.6B.100d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5U9YLp2SaxrH",
    "outputId": "3fd7e404-4bc4-4e20-c335-e179c272247f"
   },
   "outputs": [],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTRhexQVaxrC"
   },
   "source": [
    "## Step 3: Get Inputs; Split into Train and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3kot_ewaxrC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_length =  # Set input_length to 15\n",
    "\n",
    "unique_words = list(set([j.lower() for i in texts for j in i]))\n",
    "word2idx = {j:i+1 for i,j in enumerate(unique_words)}\n",
    "word2idx[\"PAD\"] = 0\n",
    "\n",
    "unique_tags = list(set([j for i in tags for j in i]))\n",
    "label2idx = {j:i for i,j in enumerate(unique_tags)}\n",
    "idx2label = {j:i for i,j in label2idx.items()}\n",
    "\n",
    "texts_train, texts_validation, tags_train, tags_validation = train_test_split(texts, tags, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train = [tf.reshape(vectorizer(s), [-1]) for s in texts_train]\n",
    "X_train = pad_sequences(maxlen = input_length, sequences = X_train, padding = \"post\", value = 0)\n",
    "\n",
    "X_validation = [tf.reshape(vectorizer(s), [-1]) for s in texts_validation]\n",
    "X_validation = pad_sequences(maxlen = input_length, sequences = X_validation, padding = \"post\", value = 0)\n",
    "\n",
    "y_train = [[label2idx[j] for j in i] for i in tags_train]\n",
    "y_train = pad_sequences(maxlen = input_length, sequences = y_train, padding = \"post\", value = 0)\n",
    "y_train = [to_categorical(i, num_classes = len(unique_tags)) for i in y_train]\n",
    "\n",
    "y_validation = [[label2idx[j] for j in i] for i in tags_validation]\n",
    "y_validation = pad_sequences(maxlen = input_length, sequences = y_validation, padding = \"post\", value = 0)\n",
    "y_validation = [to_categorical(i, num_classes = len(unique_tags)) for i in y_validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build Model with GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional, TimeDistributed, Add, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "# here, we build a model layer by layer.\n",
    "# Roughly, each layer can be thought of as a function or composition of previous layers - \n",
    "#          sometimes just the immediately precdeding layer\n",
    "#          sometimes the immediate previous layer and another previous layer.\n",
    "\n",
    "# input - straightforward\n",
    "input = Input(shape=(input_length,))\n",
    "# embedding - applied to input layer\n",
    "embedding = Embedding(input_dim=num_tokens, output_dim=100, input_length=input_length, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(input)\n",
    "# x - applied to embedding layer\n",
    "x = Bidirectional(LSTM(units=100, return_sequences=True, dropout=0.2), merge_mode = 'concat')(embedding)\n",
    "# x_rnn - applied to x layer\n",
    "x_rnn = Bidirectional(LSTM(units=100, return_sequences=True, dropout=0.2))(x)\n",
    "# x_dense\n",
    "x_dense = Add()([x, x_rnn])\n",
    "# output\n",
    "out = TimeDistributed(Dense(len(label2idx.keys()), activation=\"softmax\"))(x_dense)\n",
    "\n",
    "# create the model\n",
    "model = Model(input, out)\n",
    "# customized_model.add(Dense(len(label2idx.keys()), activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy', 'categorical_accuracy'])\n",
    "# original: categorical_crossentropy\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train GloVe-based deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit() is the training method.\n",
    "# This will output the training metrics for each epoch\n",
    "epochs =  # set epochs to 1\n",
    "\n",
    "history = model.fit(X_train, np.array(y_train), batch_size=16, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure not to run this cell more than once without resetting\n",
    "# y_validation by running the create inputs cell above\n",
    "y_pred = model.predict(X_validation)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_pred = [[idx2label[i] for i in row] for row in y_pred]\n",
    "\n",
    "y_validation = np.argmax(y_validation, axis=-1)\n",
    "y_validation = [[idx2label[i] for i in row]\n",
    "                for row in y_validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report metrics on the validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "def flat_classification_report(y_true, y_pred, digits=3):\n",
    "    report = metrics.flat_classification_report(y_true, y_pred, digits=digits)\n",
    "    report += '\\n'\n",
    "    report += '{}{: >11}'.format('sequence acc', str(round(metrics.sequence_accuracy_score(y_true, y_pred), digits)))\n",
    "    return report\n",
    "\n",
    "print(flat_classification_report(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, report the accuracy of the model as a number:\n",
    "- e.g. ***if*** the report says:\n",
    "\n",
    "    19s 67ms/step - loss: 0.3488 - accuracy: 0.9855 - categorical_accuracy: 0.8509 ...\n",
    "\n",
    "**then**\n",
    "\n",
    "accuracy = 0.9855\n",
    "- is what should be in the cell below.\n",
    "- (That is just an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy =  # report accuracy (copy and paste accuracy number from the report above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9e8291d6b4fff7d36a827d5cf14334a",
     "grade": true,
     "grade_id": "cell-3a442fd3f711b551",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Check reported accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Now Tweak Parameters\n",
    "- Now the LSTM model is performing at some particular level.\n",
    "- There are many reasons for it, but, luckily, there are a couple of things we can do right away to tune this model and improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter 1:  Epochs\n",
    "### One  simple way to improve performance a lot of the time will be adjusting the epochs.\n",
    "- Each epoch will represent another chance for the model to be better.\n",
    "- When adding epochs, a tradeoff you will face in the real world is time.  See if you can squeeze slightly better performance out of your model by adding more epochs.\n",
    "- There is a trade off between training time and performance, and you will get diminishing returns quickly.  Since each cell is time-limited on this platform, try to see how low you can set the epochs and still meet the accuracy threshold.  In this case, epochs will increase time linearly, such that changing from 2 to 4 will essentially double training time.\n",
    "- See if you can get the model to at least .91 accuracy on the validation set!\n",
    "- If you time out, it might affect your final grade drastically! Only use epochs you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f58a29b4ecceff0c89e8413b0479b56",
     "grade": false,
     "grade_id": "cell-6229ed893906d31c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import CategoricalCrossentropy\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs2 =  # increase epochs here!\n",
    "\n",
    "history2 = model.fit(X_train,np.array(y_train),batch_size=16,epochs=epochs2,validation_split=0.1)\n",
    "\n",
    "print(\"fit done\")\n",
    "\n",
    "y_pred2 = model.predict(X_validation)\n",
    "y_pred2 = np.argmax(y_pred2, axis=-1)\n",
    "y_pred2 = [[idx2label[i] for i in row] for row in y_pred2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report metrics on the validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_classification_report(y_true, y_pred, digits=3):\n",
    "    report = metrics.flat_classification_report(y_true, y_pred, digits=digits)\n",
    "    report += '\\n'\n",
    "    report += '{}{: >11}'.format('sequence acc', str(round(metrics.sequence_accuracy_score(y_true, y_pred), digits)))\n",
    "    return report\n",
    "\n",
    "report = flat_classification_report(y_pred=y_pred2, y_true=y_validation, digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "862f87a7960d9a3e6aa528ad210a2eb1",
     "grade": true,
     "grade_id": "cell-32171183c3e42c60",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test epochs.  No need to submit accuracy, but do make sure it has increased to the desired level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter 2: input length\n",
    "### Another option available to you is changing how many tokens to use for each input\n",
    "- Every input must have the same length.\n",
    "- This why we need to explicitly set it in both the input creation and model-building processes.\n",
    "- We are potentially losing a lot of information by setting our input length to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell and...\n",
    "# See how we are cutting some sentences short\n",
    "print(\"length of actual sentence:\", len(texts[132]))\n",
    "print(\"length of used sentence:  \", len(X_train[132]))\n",
    "# Uncomment the following to see how much would be missing\n",
    "print(texts[132][:50], '\\b\\b, ...]\\n\\nBecomes\\n')\n",
    "print(texts[132][:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remember, this should also be the input_length parameter of the Embedding layer, hence using the same variable to set both.\n",
    "- You could run the above and below cell again each time you change the input_length variable to see updated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Run this cell)\n",
    "# But there are examples like this as well:\n",
    "print(\"actual:      \", len(texts[113]))\n",
    "print(\"fed to model:\", len(X_train[113]))\n",
    "print(texts[113])\n",
    "print(X_train[113])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before moving on, try to think about the tradeoffs of increasing or decreasing the input length.\n",
    "- Intuitively, what are the benefits of increasing input length?\n",
    "- What are the drawbacks to increasing input length?\n",
    "\n",
    "\n",
    "- What about the pros and cons of having a lower input length?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try changing the input length, which will be the maxlen parameter of pad_sequences() and the input length parameter in the model input, to another number (keep it under 60) and see how it impacts performance.\n",
    "- In particular, set the input_length2 variable below to a number that results in an accuracy of at least 0.95!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set new input length.  Create new inputs with new input length.  Increase it (from the original 15), but definitely keep it below 60!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length2 =   # set input length.\n",
    "\n",
    "X_train2 = [tf.reshape(vectorizer(s), [-1]) for s in texts_train]\n",
    "X_train2 = pad_sequences(maxlen = input_length2, sequences = X_train2, padding = \"post\", value = 0)\n",
    "\n",
    "X_validation2 = [tf.reshape(vectorizer(s), [-1]) for s in texts_validation]\n",
    "X_validation2 = pad_sequences(maxlen = input_length2, sequences = X_validation2, padding = \"post\", value = 0)\n",
    "\n",
    "y_train2 = [[label2idx[j] for j in i] for i in tags_train]\n",
    "y_train2 = pad_sequences(maxlen = input_length2, sequences = y_train2, padding = \"post\", value = 0)\n",
    "y_train2 = [to_categorical(i, num_classes = len(unique_tags)) for i in y_train2]\n",
    "\n",
    "y_validation2 = [[label2idx[j] for j in i] for i in tags_validation]\n",
    "y_validation2 = pad_sequences(maxlen = input_length2, sequences = y_validation2, padding = \"post\", value = 0)\n",
    "y_validation2 = [to_categorical(i, num_classes = len(unique_tags)) for i in y_validation2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new model with new input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional, TimeDistributed, Add, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "input2 = Input(shape=(input_length2,))\n",
    "embedding2 = Embedding(input_dim=num_tokens, output_dim=100, input_length=input_length2, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(input2)\n",
    "x2 = Bidirectional(LSTM(units=100, return_sequences=True, dropout=0.2), merge_mode = 'concat')(embedding2)\n",
    "x_rnn2 = Bidirectional(LSTM(units=100, return_sequences=True, dropout=0.2))(x2)\n",
    "x_dense2 = Add()([x2, x_rnn2])\n",
    "out2 = TimeDistributed(Dense(len(label2idx.keys()), activation=\"softmax\"))(x_dense2)\n",
    "model2 = Model(input2, out2)\n",
    "# customized_model.add(Dense(len(label2idx.keys()), activation=\"softmax\"))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy', 'categorical_accuracy'])\n",
    "# original: categorical_crossentropy\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs3 =  epochs2 # You can change epochs here\n",
    "\n",
    "history3 = model2.fit(X_train2,np.array(y_train2),batch_size=16,epochs=epochs3,validation_split=0.1)\n",
    "\n",
    "print(\"fit done\")\n",
    "\n",
    "y_pred3 = model2.predict(X_validation2)\n",
    "y_pred3 = np.argmax(y_pred3, axis=-1)\n",
    "y_pred3 = [[idx2label[i] for i in row] for row in y_pred3]\n",
    "\n",
    "y_validation2 = np.argmax(y_validation2, axis=-1)\n",
    "y_validation2 = [[idx2label[i] for i in row]\n",
    "                for row in y_validation2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report metrics on the validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = flat_classification_report(y_pred=y_pred3, y_true=y_validation2, digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Play with the input length and epochs a few times until you are able to find where the accuracy is great, but you haven't drastically increased the run time.\n",
    "\n",
    "- There will always be one more tweak you can do to make your model better, but, for this lab, just try to get a feel for when it is not improving much at anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd09e10d60dc83da5ca0ef26c3f1827e",
     "grade": true,
     "grade_id": "cell-cace115c8ff6094d",
     "locked": true,
     "points": 40,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for setting input_length2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPORT YOUR FINAL ACCURACY HERE:\n",
    "accuracy_final =    # fill this in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7ad38b30102b96687607938a3896ef3",
     "grade": true,
     "grade_id": "cell-bc5c65e48fd02f69",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last assignment, we focused on macro-averaged F1. Note that this increased as well when accuracy did in this particular setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Notes:\n",
    "### Think about what some possible reasons for this model's performance to increase with higher input length.\n",
    "### And think about other limitations of the way we evaluated performance.\n",
    "- How is the data changing, and how might that make it easier for the model to get more right?\n",
    "- Accuracy may have been high, but you might notice that not all classes are being identified well.  Think about what could have been a better measure of your model's success!  What was the purpose of the task?  What combination of metrics would better represent successfully completing that task?  Notice that it is not immediately obvious how best to evaluate performance on this task!\n",
    "\n",
    "### Deep Learning Model\n",
    "- Depending on your exact feature engineering choices from the last assignment, you may see that this approach performed better or worse, but in whatever case, this one required a bit less effort. There was a lot of setup, but it sort of did all of the work. However, you may also feel that, with this approach, there was more mystery surrounding what was going on. The previous (CRF) model used features that you created, while this model seems to learn useful things, but exactly what kind of relationships it is learning are harder to see.\n",
    "- Think about whether you have problems with that. Should we be able to explain the models we are deploying reasonably well, or is it okay just to choose the best performing model?  Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "MOOC_week4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
